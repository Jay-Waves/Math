## 哈夫曼 (Huffman) 编码

通过构建二叉树来编码: (自底向下)
1. 为每个符号创建一个节点, 权值为其出现概率.
2. 按权值从小到大排序节点, 使用优先队列存储.
3. 构建树:
	- 选出权值最小两个节点
	- 创建新内部节点, 作为这两个节点父节点, 其权值为两子节点权值和.
	- 将新节点添加回优先队列, 重新排序
	- 重复该过程, 直至只剩根节点.
4. 分配码字, 从根开始, 向左分配0, 向右分配1.

使用二叉树译码, 顺序读入二进制编码, 从root开始, 对于每个编码:
- 读1进入左子树
- 读0进入右子树
- 若到达叶子节点, 则译出一个符号.

## 香农 (Shannon-Fano) 编码

香农编码思想是通过累加概率, 根据每个符号出现概率, 为其分配一个 $[0,1)$ 的概率区间. 若有 $k$ 个码字, 则有 $\sum\limits^{k}_{i=1}P_{i}=1$, 其中 $P_{i}$ 为码 $W_{i}$ 出现概率.

1. 将灰度级按出现概率从大到小排列
2. 计算码字长度 $-\log_{2}P_{i} \le \beta_{i}<-\log_{2}P_{i}+1$
3. 计算累加概率: $$\begin{align}
a_{1}&=0 \\
a_{2}&=P_{1} \\
a_{3}&=P_{2}+a_{2} =P_{2}+P_{1} \\
a_{4}&=P_{3}+a_{3} =P_{3}+P_{2}+P_{1} \\
\vdots \\
a_{i}&=P_{i-1}+P_{i-2}+\dots+P_{1}
\end{align}$$
4. 将 $a_{i}$ 十进制转二进制
5. 去除多余尾数, 补至 $\beta_{i}$ 长.

**香农编码效率低于哈夫曼编码**

## 算术编码

算术编码思想是选定一个区间来定义(代表)整个消息序列, 而不是寻求符号和码字的一一对应. **信源均匀情况下, 传输的符号概率表体积很小, 其编码效率甚至可高于哈夫曼编码**

举个例子来理解其编码过程: 假设四个符号 $A, B, C, D$, 概率分别为 $0.4, 0.3, 0.2, 0.1$. 此时对消息 "AB" 进行编码:
- 初始化区间 $[0, 1)$
- 处理消息符号A, 将区间划分为:$$\begin{align}
A:& [0, 0.4) \\
B:& [0.4, 0.7)  \\
C:& [0.7, 0.9)  \\
D:& [0.9, 1.0)
\end{align}$$ 此后选取 $[0, 0.4)$ 为新编码空间.
- 处理消息符号B, 将 $[0, 0.4)$ 划分为:$$\begin{align}
A:& [0, 0.16) \\
B:& [0.16, 0.28)  \\
C:& [0.28, 0.36) \\
D:& [0.36, 0.4)
\end{align}$$ 此后选取 $[0.36, 0.4)$ 为新编码空间.
- 消息处理完毕, 消息"AB"的编码区间为 $[0.36, 0.4)$, 区间中任意实数都可以唯一标识这个消息"AB"